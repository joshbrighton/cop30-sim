<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>COP30 Simulation</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <style>
    body {
      margin: 0;
      padding: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      background: #f7f7f7;
      display: flex;
      justify-content: center;
      align-items: center;
      min-height: 100vh;
    }

    .container {
      width: 90%;
      max-width: 650px;
      background: white;
      padding: 40px;
      border-radius: 12px;
      box-shadow: 0 6px 20px rgba(0, 0, 0, 0.1);
      text-align: center;
    }

    .mic {
      width: 90px;
      height: 90px;
      border-radius: 50%;
      background: #004ea4;
      display: flex;
      justify-content: center;
      align-items: center;
      margin: 0 auto;
      cursor: pointer;
      transition: transform 0.15s ease;
    }

    .mic svg {
      width: 40px;
      height: 40px;
      fill: white;
    }

    .active {
      animation: pulse 1.5s infinite;
    }

    @keyframes pulse {
      0% { box-shadow: 0 0 0 0 rgba(0, 78, 164, 0.6); }
      70% { box-shadow: 0 0 0 15px rgba(0, 78, 164, 0); }
      100% { box-shadow: 0 0 0 0 rgba(0, 78, 164, 0); }
    }
  </style>
</head>

<body>
  <div class="container">
    <h1>COP30 Media Simulation</h1>
    <p>Click the microphone to begin. When activated, say “Ok, I’m ready.”</p>

    <div class="mic" id="micButton">
      <svg viewBox="0 0 24 24">
        <path d="M12 14a3 3 0 0 0 3-3V5a3 3 0 0 0-6 0v6a3 3 0 0 0 3 3zm5-3a5 5 0 0 1-10 0H5a7 7 0 0 0 14 0h-2zm-5 7a9 9 0 0 0 9-9h-2a7 7 0 0 1-14 0H3a9 9 0 0 0 9 9zm-1 2v2h2v-2h-2z"/>
      </svg>
    </div>
  </div>

  <script>
    let audioContext;
    let micStream;
    let ws;

    async function startSimulation() {
      const micButton = document.getElementById("micButton");
      micButton.classList.add("active");

      // Step 1: Call your Vercel API to get Retell session URL
      const sessionRes = await fetch("/api/retell");

      if (!sessionRes.ok) {
        alert("Could not start the session. API error.");
        console.error(await sessionRes.text());
        return;
      }

      const session = await sessionRes.json();

      // Step 2: Connect to Retell WebSocket
      ws = new WebSocket(session.url);
      ws.binaryType = "arraybuffer";

      ws.onopen = () => console.log("Connected to Retell");

      ws.onerror = (err) => console.error("WebSocket error:", err);

      // Step 3: Capture microphone audio
      audioContext = new AudioContext();
      micStream = await navigator.mediaDevices.getUserMedia({ audio: true });

      const source = audioContext.createMediaStreamSource(micStream);
      const processor = audioContext.createScriptProcessor(4096, 1, 1);

      source.connect(processor);
      processor.connect(audioContext.destination);

      processor.onaudioprocess = (e) => {
        if (ws.readyState === WebSocket.OPEN) {
          const float32 = e.inputBuffer.getChannelData(0);
          const int16 = new Int16Array(float32.length);

          for (let i = 0; i < float32.length; i++)
            int16[i] = float32[i] * 32767;

          ws.send(int16);
        }
      };

      // Step 4: Play bot audio
      ws.onmessage = (msg) => {
        const int16 = new Int16Array(msg.data);
        const float32 = new Float32Array(int16.length);

        for (let i = 0; i < int16.length; i++)
          float32[i] = int16[i] / 32767;

        const buffer = audioContext.createBuffer(1, float32.length, audioContext.sampleRate);
        buffer.getChannelData(0).set(float32);

        const playback = audioContext.createBufferSource();
        playback.buffer = buffer;
        playback.connect(audioContext.destination);
        playback.start();
      };
    }

    document.getElementById("micButton").onclick = startSimulation;
  </script>
</body>
</html>
